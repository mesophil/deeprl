# -*- coding: utf-8 -*-
"""TinyImageNetLoader.ipynb

Automatically generated by Colaboratory.


"""

import torch
from torch.utils.data import Dataset
import os, glob
from torchvision.io import read_image, ImageReadMode

class TrainTinyImageNetDataset(Dataset):
    def __init__(self, id, path, transform=None):
        self.master_path = path # /path/ending/in/tiny-imagenet-200/
        self.filenames = glob.glob(os.path.join(self.master_path, "train/*/*/*.JPEG"))
        self.transform = transform
        self.id_dict = id

    def __len__(self):
        return len(self.filenames)

    def __getitem__(self, idx):
        img_path = self.filenames[idx]
        image = read_image(img_path)
        if image.shape[0] == 1:
          image = read_image(img_path,ImageReadMode.RGB)
        label = self.id_dict[img_path.split('/')[4]]
        if self.transform:
            image = self.transform(image.type(torch.FloatTensor))
        return image, label

class TestTinyImageNetDataset(Dataset):
    def __init__(self, id, path, transform=None):
        self.master_path = path # /path/ending/in/tiny-imagenet-200/
        self.filenames = glob.glob(os.path.join(self.master_path, "val/images/*.JPEG"))
        self.transform = transform
        self.id_dict = id
        self.cls_dic = {}
        for i, line in enumerate(open("".join([self.master_path, 'val/val_annotations.txt']), 'r')):
            a = line.split('\t')
            img, cls_id = a[0],a[1]
            self.cls_dic[img] = self.id_dict[cls_id]
 

    def __len__(self):
        return len(self.filenames)

    def __getitem__(self, idx):
        img_path = self.filenames[idx]
        image = read_image(img_path)
        if image.shape[0] == 1:
          image = read_image(img_path,ImageReadMode.RGB)
        label = self.cls_dic[img_path.split('/')[-1]]
        if self.transform:
            image = self.transform(image.type(torch.FloatTensor))

        print(idx)
        return image, label